{
    "vocab_size": 262144,
    "hidden_size": 1024,
    "num_hidden_layers": 16,
    "num_attention_heads": 16,
    "num_key_value_heads": 4,
    "intermediate_size": 4096,
    "sequence_length": 2048,
    "activation_function": "swiGLU",
    "max_position_embeddings": 2048,

    "batch_size": 32,
    "micro_batch_size": 2,
    "inner_steps": 10,
    "outer_learning_rate": 0.2,
    "blocks_per_window": 8,
    "time_window_delta_seconds": 80,
    
    "checkpoint_init_version": null,
    "checkpoint_init_window": null,
    "torchtitan": {
        "enable_async_tensor_parallel": false
      }
}
