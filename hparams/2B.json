{
    "vocab_size": 262144,
    "hidden_size": 1024,
    "num_hidden_layers": 16,
    "num_attention_heads": 16,
    "num_key_value_heads": 4,
    "intermediate_size": 4096,
    "sequence_length": 2048,
    "activation_function": "swiGLU",
    "max_position_embeddings": 2048,

    "batch_size": 32,
    "micro_batch_size": 1,
    "inner_steps": 10,
    "outer_learning_rate": 0.15,
    "blocks_per_window": 5,
    "time_window_delta_seconds": 50,
    
    "checkpoint_init_version": null,
    "checkpoint_init_window": null,
    "torchtitan": {
        "enable_async_tensor_parallel": false,
        "tie_model_and_embeddings": false
      }
}
