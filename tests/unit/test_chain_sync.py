import pytest
from unittest.mock import MagicMock, AsyncMock, patch
from types import SimpleNamespace
import torch
import asyncio
from tests.mocks.subtensor import MockSubtensor
from tests.mocks.wallet import MockWallet
from tests.mocks.metagraph import MockMetagraph

from tplr.chain_sync import ChainSync
from tplr.schemas import Bucket

# Import existing mocks

# Mark all tests as async
# pytestmark = pytest.mark.asyncio


class TestChainSyncBasics:
    """Test basic initialization and attributes of ChainSync"""

    @pytest.fixture
    async def chain_sync_instance(self, mock_wallet, mock_metagraph):
        """Create chain sync instance with standard mocks"""
        config = MagicMock()
        netuid = 1

        # Use existing mocks
        hparams = SimpleNamespace(
            blocks_per_window=100,
            topk_peers=10,
            minimum_peers=3,
            max_topk_peers=10,
            eval_stake_threshold=20000,
        )

        # Create instance
        chain_sync = ChainSync(
            config=config,
            netuid=netuid,
            metagraph=mock_metagraph,
            hparams=hparams,
            fetch_interval=60,
            wallet=mock_wallet,
        )

        return chain_sync

    async def test_initialization(self, chain_sync_instance):
        """Test ChainSync initialization"""
        # Check basic attributes
        assert chain_sync_instance.netuid == 1
        assert chain_sync_instance.window_duration == 100
        assert chain_sync_instance.current_block == 0
        assert chain_sync_instance.current_window == 0

        # Check collections
        assert isinstance(chain_sync_instance.commitments, dict)
        assert isinstance(chain_sync_instance.peers, list)
        assert isinstance(chain_sync_instance.eval_peers, dict)
        assert isinstance(chain_sync_instance.active_peers, set)
        assert isinstance(chain_sync_instance.inactive_peers, set)


class TestCommitmentManagement:
    """Test commitment fetching and management"""

    @pytest.fixture
    async def chain_sync_instance(self, mock_wallet, mock_metagraph):
        """Create chain sync instance with mocked commitments"""
        # Setup hparams
        hparams = SimpleNamespace(
            blocks_per_window=100, topk_peers=10, minimum_peers=3, max_topk_peers=10
        )

        # Create instance
        chain_sync = ChainSync(
            config=MagicMock(),
            netuid=1,
            metagraph=mock_metagraph,
            hparams=hparams,
            wallet=mock_wallet,
        )

        # Mock subtensor method
        chain_sync.subtensor = MagicMock()
        chain_sync.get_commitments = AsyncMock(return_value={})

        # Add some bucket info manually
        chain_sync.commitments = {
            1: Bucket(
                name="bucket1",
                account_id="account1",
                access_key_id="key1",
                secret_access_key="secret1",
            ),
            2: Bucket(
                name="bucket2",
                account_id="account2",
                access_key_id="key2",
                secret_access_key="secret2",
            ),
            3: Bucket(
                name="bucket3",
                account_id="account3",
                access_key_id="key3",
                secret_access_key="secret3",
            ),
        }

        return chain_sync

    async def test_get_bucket(self, chain_sync_instance):
        """Test getting a bucket for a specific UID"""
        # Get bucket for existing UID
        bucket = chain_sync_instance.get_bucket(1)
        assert bucket is not None
        assert bucket.name == "bucket1"

        # Get bucket for non-existing UID
        bucket = chain_sync_instance.get_bucket(999)
        assert bucket is None


class TestPeerTracking:
    """Test peer tracking and selection"""

    @pytest.fixture
    async def chain_sync_instance(self):
        """Create chain sync instance with mock peer data"""
        # Setup hyperparameters
        hparams = SimpleNamespace(
            blocks_per_window=100,
            topk_peers=10,      # 10% of peers
            minimum_peers=3,
            max_topk_peers=10,
        )

        # Create a mock metagraph with 10 validators.
        metagraph = MockMetagraph(n_validators=10)
        # Create a dummy wallet.
        wallet = MockWallet()

        # Instantiate ChainSync with the mocks.
        chain_sync = ChainSync(
            config=MagicMock(),
            netuid=1,
            metagraph=metagraph,
            hparams=hparams,
            wallet=wallet,
        )

        return chain_sync

    async def test_set_gather_peers_empty_active_peers(self, chain_sync_instance):
        """
        If active_peers is empty, set_gather_peers() should select peers based solely on 
        the entire metagraph, since the current implementation ignores active_peers.
        """
        # Set active_peers to empty. (Ignored by set_gather_peers())
        chain_sync_instance.active_peers = set()
        peers = chain_sync_instance.set_gather_peers()

        # Using MockMetagraph with n_validators=10, the incentive tensor is:
        # I = [0.5, 0.6, 0.7, ..., 1.4]. Sorted descending, the top three UIDs are [9, 8, 7].
        expected_peers = [9, 8, 7]
        assert peers == expected_peers, f"Expected {expected_peers}, got {peers}"


class TestValidatorIdentification:
    """Test finding highest staked validator"""

    @pytest.fixture
    async def chain_sync_instance(self, mock_wallet, mock_metagraph):
        """Create chain sync instance with validators in metagraph"""
        # Setup hparams
        hparams = SimpleNamespace(blocks_per_window=100)

        # Create instance
        chain_sync = ChainSync(
            config=MagicMock(),
            netuid=1,
            metagraph=mock_metagraph,
            hparams=hparams,
            wallet=mock_wallet,
        )

        # Add bucket info
        chain_sync.commitments = {
            0: Bucket(
                name="bucket0",
                account_id="account0",
                access_key_id="key0",
                secret_access_key="secret0",
            ),
            1: Bucket(
                name="bucket1",
                account_id="account1",
                access_key_id="key1",
                secret_access_key="secret1",
            ),
            2: Bucket(
                name="bucket2",
                account_id="account2",
                access_key_id="key2",
                secret_access_key="secret2",
            ),
            3: Bucket(
                name="bucket3",
                account_id="account3",
                access_key_id="key3",
                secret_access_key="secret3",
            ),
            4: Bucket(
                name="bucket4",
                account_id="account4",
                access_key_id="key4",
                secret_access_key="secret4",
            ),
            5: Bucket(
                name="bucket5",
                account_id="account5",
                access_key_id="key5",
                secret_access_key="secret5",
            ),
            6: Bucket(
                name="bucket6",
                account_id="account6",
                access_key_id="key6",
                secret_access_key="secret6",
            ),
            7: Bucket(
                name="bucket7",
                account_id="account7",
                access_key_id="key7",
                secret_access_key="secret7",
            ),
            8: Bucket(
                name="bucket8",
                account_id="account8",
                access_key_id="key8",
                secret_access_key="secret8",
            ),
            9: Bucket(
                name="bucket9",
                account_id="account9",
                access_key_id="key9",
                secret_access_key="secret9",
            ),
        }

        return chain_sync

    async def test_get_highest_stake_validator(self, chain_sync_instance):
        """Test finding the highest staked validator"""
        # Get highest stake validator bucket
        bucket, uid = await chain_sync_instance._get_highest_stake_validator_bucket()

        # Check that we got a bucket and a UID (specific values depend on mock metagraph)
        assert bucket is not None
        assert uid is not None
        # The bucket name should follow our format
        assert bucket.name == f"bucket{uid}"

    async def test_no_validators(self):
        """Test handling when no validators exist"""
        # Create metagraph with no validators (all trust = 0)
        metagraph = MagicMock()
        metagraph.uids = torch.tensor([1, 2, 3])
        metagraph.T = torch.tensor([0.0, 0.0, 0.0])

        # Create instance
        chain_sync = ChainSync(
            config=MagicMock(),
            netuid=1,
            metagraph=metagraph,
            hparams=SimpleNamespace(blocks_per_window=100),
        )

        # Get highest stake validator bucket (should be None)
        bucket, uid = await chain_sync._get_highest_stake_validator_bucket()
        assert bucket is None
        assert uid is None


class TestFetchBackground:
    """Test background fetching task"""

    @pytest.fixture
    async def chain_sync_instance(self, mock_wallet, mock_metagraph):
        """Create chain sync instance for testing background fetching"""
        # Create instance
        chain_sync = ChainSync(
            config=MagicMock(),
            netuid=1,
            metagraph=mock_metagraph,
            hparams=SimpleNamespace(blocks_per_window=100),
            fetch_interval=0.1,  # Fast interval for testing
            wallet=mock_wallet,
        )

        # Mock methods used by background task
        chain_sync.get_commitments = AsyncMock(return_value={1: MagicMock()})
        chain_sync.update_peers_with_buckets = MagicMock()

        # Mock the periodic task to prevent it from actually running
        chain_sync._fetch_commitments_periodically = AsyncMock()

        yield chain_sync

        # Clean up the task if it exists
        if chain_sync._fetch_task is not None:
            chain_sync._fetch_task.cancel()

    async def test_commitment_fetcher_start(self, chain_sync_instance):
        """Test starting the commitment fetcher"""
        # Initially no task
        assert chain_sync_instance._fetch_task is None

        # Patch create_task to track if it was called
        with patch("asyncio.create_task") as mock_create_task:
            chain_sync_instance.start_commitment_fetcher()
            mock_create_task.assert_called_once()

        # Task should be set
        assert chain_sync_instance._fetch_task is not None


class TestErrorHandling:
    """Test error handling in ChainSync"""

    @pytest.fixture
    async def chain_sync_instance(self, mock_wallet, mock_metagraph):
        """Create chain sync instance for testing error handling"""
        chain_sync = ChainSync(
            config=MagicMock(),
            netuid=1,
            metagraph=mock_metagraph,
            hparams=SimpleNamespace(blocks_per_window=100),
            wallet=mock_wallet,
        )

        return chain_sync

    async def test_get_commitments_error(self, chain_sync_instance):
        """Test error handling in get_commitments"""
        # Simply mock the get_commitments method directly
        # This is simpler and avoids the issue with unawaited coroutines
        with patch.object(
            chain_sync_instance, "get_commitments", new_callable=AsyncMock
        ) as mock_get_commitments:
            # Set up the mock to return empty dict
            mock_get_commitments.return_value = {}

            # Call the method and verify result
            commitments = await chain_sync_instance.get_commitments()
            assert commitments == {}

            # Verify the mock was called
            mock_get_commitments.assert_awaited_once()

        # Now test with the real implementation handling an exception
        if (
            hasattr(chain_sync_instance, "subtensor")
            and chain_sync_instance.subtensor is not None
        ):
            # Only if subtensor already exists
            orig_subtensor = chain_sync_instance.subtensor
            try:
                # Create a mock that raises an exception
                mock_subtensor = MagicMock()

                # We'll use side_effect to define what happens when method is called
                async def mock_get_commitment(*args, **kwargs):
                    raise Exception("Test error")

                mock_subtensor.get_commitment = mock_get_commitment
                chain_sync_instance.subtensor = mock_subtensor

                # Test the exception handling
                result = await chain_sync_instance.get_commitments()
                assert result == {}
            finally:
                # Restore original
                chain_sync_instance.subtensor = orig_subtensor

    async def test_get_highest_validator_error(self, chain_sync_instance):
        """Test error handling in get_highest_stake_validator_bucket"""
        # Make metagraph raise an exception on access
        chain_sync_instance.metagraph.uids = MagicMock(
            side_effect=Exception("Test error")
        )

        # Should return None, None on error
        bucket, uid = await chain_sync_instance._get_highest_stake_validator_bucket()
        assert bucket is None
        assert uid is None


async def test_periodic_commitment_fetcher():
    """
    Test that the periodic commitment fetcher in ChainSync calls
    get_commitments repeatedly.
    """
    hparams = SimpleNamespace(
        blocks_per_window=100,
        topk_peers=10,
        minimum_peers=1,
        max_topk_peers=5,
        eval_stake_threshold=20000,
    )

    commitment_calls = 0

    async def fake_get_commitments(*args, **kwargs):
        nonlocal commitment_calls
        commitment_calls += 1
        # Return a dummy commitment for each call.
        return {
            commitment_calls: Bucket(
                name=f"bucket{commitment_calls}",
                account_id=f"acc{commitment_calls}",
                access_key_id="dummy_key",
                secret_access_key="dummy_secret",
            )
        }

    # Patch ChainSync.get_commitments and bt.subtensor.
    with patch(
        "tplr.chain_sync.ChainSync.get_commitments",
        new=AsyncMock(side_effect=fake_get_commitments),
    ):
        with patch("tplr.chain_sync.bt.subtensor", return_value=MockSubtensor()):
            # Create a metagraph instance from our mocks and attach a dummy sync.
            metagraph = MockMetagraph()
            metagraph.sync = lambda subtensor: None

            chain_sync = ChainSync(
                config=MagicMock(),
                netuid=1,
                metagraph=metagraph,
                hparams=hparams,
                fetch_interval=0.1,
                wallet=MockWallet(),
            )

            fetch_task = asyncio.create_task(
                chain_sync._fetch_commitments_periodically()
            )
            await asyncio.sleep(0.35)  # allow for a few iterations
            fetch_task.cancel()
            try:
                await fetch_task
            except asyncio.CancelledError:
                pass

    # Expect at least 3 calls (0.35/0.1 ≈ 3-4 iterations)
    assert commitment_calls >= 3


async def test_update_peers_with_buckets():
    """
    Test that ChainSync correctly updates its peers list based on the intersection
    of active peers and available commitment buckets.
    """
    hparams = SimpleNamespace(
        blocks_per_window=100, topk_peers=10, minimum_peers=1, max_topk_peers=5
    )
    chain_sync = ChainSync(
        config=MagicMock(),
        netuid=1,
        metagraph=MagicMock(),
        hparams=hparams,
        wallet=MagicMock(),
    )

    # Set some dummy commitments and active peers.
    chain_sync.commitments = {
        1: Bucket(
            name="bucket1",
            account_id="acc1",
            access_key_id="k1",
            secret_access_key="s1",
        ),
        2: Bucket(
            name="bucket2",
            account_id="acc2",
            access_key_id="k2",
            secret_access_key="s2",
        ),
    }
    # Active peers include one extra peer (3) that lacks a commitment.
    chain_sync.active_peers = {1, 2, 3}
    # Update peers by taking an intersection.
    chain_sync.peers = list(
        chain_sync.active_peers.intersection(chain_sync.commitments.keys())
    )

    # Only UIDs 1 and 2 should be in peers.
    assert set(chain_sync.peers) == {1, 2}


async def test_window_update_on_block():
    """
    Test that updating the current block value leads to recalculating the current window.
    """
    hparams = SimpleNamespace(
        blocks_per_window=10, topk_peers=10, minimum_peers=1, max_topk_peers=5
    )
    chain_sync = ChainSync(
        config=MagicMock(),
        netuid=1,
        metagraph=MagicMock(),
        hparams=hparams,
        wallet=MagicMock(),
    )
    # Initialize current block and window.
    chain_sync.current_block = 5
    chain_sync.current_window = 0

    # Simulate a block update:
    def fake_block_update(new_block: int):
        chain_sync.current_block = new_block
        new_window = int(new_block / hparams.blocks_per_window)
        if new_window != chain_sync.current_window:
            chain_sync.current_window = new_window

    fake_block_update(25)  # 25 // 10 = 2
    assert chain_sync.current_window == 2


async def test_get_bucket_not_found():
    """
    Test that get_bucket returns None for an unknown UID.
    """
    hparams = SimpleNamespace(
        blocks_per_window=100, topk_peers=10, minimum_peers=1, max_topk_peers=5
    )
    chain_sync = ChainSync(
        config=MagicMock(),
        netuid=1,
        metagraph=MagicMock(),
        hparams=hparams,
        wallet=MagicMock(),
    )
    # Set commitments with UID 1 only.
    chain_sync.commitments = {
        1: Bucket(
            name="bucket1",
            account_id="acc1",
            access_key_id="key1",
            secret_access_key="secret1",
        )
    }
    bucket = chain_sync.get_bucket(999)
    assert bucket is None


# ------------------------------------------------------------
# Test get_commitments() with various commitment cases.
# ------------------------------------------------------------


# @pytest.mark.asyncio
# async def test_get_commitments_various_cases():
#     """
#     Tests get_commitments() with:
#       - Valid commitment (length 128) for uid=1.
#       - Empty commitment for uid=2.
#       - Invalid length commitment for uid=3.
#       - Exception raised for uid=4.
#     Only uid=1 should yield a Bucket.
#     """
#     # Create a dummy metagraph with uids.
#     metagraph = MagicMock()
#     metagraph.uids = torch.tensor([1, 2, 3, 4])

#     # Instantiate ChainSync.
#     cs = ChainSync(
#         config=MagicMock(),
#         netuid=1,
#         metagraph=metagraph,
#         hparams=SimpleNamespace(),
#         wallet=MagicMock(),
#         fetch_interval=1,
#     )

#     # Create a fake subtensor with custom get_commitment.
#     class FakeSubtensor:
#         async def get_commitment(self, netuid, uid):
#             if uid == 1:
#                 return "a" * 128  # valid
#             elif uid == 2:
#                 return ""  # empty
#             elif uid == 3:
#                 return "b" * 50  # invalid length
#             elif uid == 4:
#                 raise Exception("dummy error")

#     fake_subtensor = FakeSubtensor()

#     cs.subtensor = fake_subtensor
#     commitments = await cs.get_commitments()

#     # Only uid 1 should be added.
#     assert 1 in commitments
#     assert commitments[1].name == "a" * 32
#     assert 2 not in commitments
#     assert 3 not in commitments
#     assert 4 not in commitments


# ------------------------------------------------------------
# Test update_peers_with_buckets() and set_gather_peers()
# ------------------------------------------------------------


def test_update_peers_with_empty_active_peers():
    """
    If active_peers is empty, update_peers_with_buckets() should warn
    and leave peers empty while marking previously active peers as inactive.
    """
    metagraph = MagicMock()
    metagraph.uids = torch.tensor([1, 2, 3])
    metagraph.S = torch.tensor([100, 200, 300])
    metagraph.I = torch.tensor([10, 20, 30])

    hparams = SimpleNamespace(
        eval_stake_threshold=20000, topk_peers=10, minimum_peers=3, max_topk_peers=10
    )
    cs = ChainSync(
        config=MagicMock(),
        netuid=1,
        metagraph=metagraph,
        hparams=hparams,
        wallet=MagicMock(),
        fetch_interval=1,
    )

    # Prepopulate eval_peers so we can see the difference.
    cs.eval_peers = {1: 5, 2: 3}
    cs.active_peers = set()  # empty active peers

    cs.update_peers_with_buckets()
    assert cs.peers == []  # No peers gathered.
    # All previously active should now be inactive.
    assert cs.inactive_peers == {1, 2}


def test_update_peers_with_nonempty_active_peers():
    """
    With non-empty active_peers, update_peers_with_buckets() should filter
    eval_peers based on stake threshold and set gather peers ordering by incentive.
    """
    metagraph = MagicMock()
    metagraph.uids = torch.tensor([1, 2, 3])
    # Stakes: uid1=15000, uid2=25000, uid3=18000.
    metagraph.S = torch.tensor([15000, 25000, 18000])
    # Incentives: uid1=100, uid2=200, uid3=50.
    metagraph.I = torch.tensor([100, 200, 50])

    hparams = SimpleNamespace(
        eval_stake_threshold=20000, topk_peers=10, minimum_peers=3, max_topk_peers=10
    )
    cs = ChainSync(
        config=MagicMock(),
        netuid=1,
        metagraph=metagraph,
        hparams=hparams,
        wallet=MagicMock(),
        fetch_interval=1,
    )

    cs.active_peers = {1, 2, 3}
    cs.eval_peers = {}  # start with empty eval_peers.

    cs.update_peers_with_buckets()
    # Only uid=1 and uid=3 have stakes <=20000.
    assert cs.eval_peers == {1: 1, 3: 1}
    # set_gather_peers works on active_peers regardless.
    # Incentives sorted descending: [(2,200), (1,100), (3,50)].
    # With minimum_peers=3, peers list should be all: [2, 1, 3].
    assert cs.peers == [2, 1, 3]


def test_set_gather_peers_empty():
    """
    If active_peers is empty, set_gather_peers() should select peers based solely on 
    the entire metagraph's incentives.
    Since metagraph.uids = [1, 2] and metagraph.I = [50, 60], the sorted order is [2, 1].
    Even though minimum_peers is 3, only two peers are available.
    """
    metagraph = MagicMock()
    metagraph.uids = torch.tensor([1, 2])
    metagraph.I = torch.tensor([50, 60])
    hparams = SimpleNamespace(topk_peers=10, minimum_peers=3, max_topk_peers=10)
    cs = ChainSync(
        config=MagicMock(),
        netuid=1,
        metagraph=metagraph,
        hparams=hparams,
        wallet=MagicMock(),
        fetch_interval=1,
    )

    cs.active_peers = set()  # This field is ignored by set_gather_peers()
    cs.set_gather_peers()

    # Compute expected output:
    # Incentives: {1:50, 2:60}; sorted descending: [2, 1]
    # n_topk_peers = int(2 * (10/100)) = int(0.2) = 0, then forced to 1,
    # n_peers = max(3, 1) = 3, but only 2 peers are available, so final output is [2, 1].
    expected = [2, 1]
    assert cs.peers == expected, f"Expected {expected}, got {cs.peers}"


@pytest.mark.asyncio
async def test_get_highest_stake_validator_bucket_no_validators():
    """
    If no validators are found (all T values are 0), the method should return (None, None).
    """
    metagraph = MagicMock()
    metagraph.uids = torch.tensor([1, 2, 3])
    metagraph.S = torch.tensor([100, 200, 50])
    metagraph.T = torch.tensor([0, 0, 0])

    hparams = SimpleNamespace()
    cs = ChainSync(
        config=MagicMock(),
        netuid=1,
        metagraph=metagraph,
        hparams=hparams,
        wallet=MagicMock(),
        fetch_interval=1,
    )

    bucket, uid = await cs._get_highest_stake_validator_bucket()
    assert bucket is None
    assert uid is None


@pytest.mark.asyncio
async def test_get_highest_stake_validator_bucket_no_metagraph():
    """
    If metagraph is None, _get_highest_stake_validator_bucket() should return (None, None).
    """
    cs = ChainSync(
        config=MagicMock(),
        netuid=1,
        metagraph=None,
        hparams=SimpleNamespace(),
        wallet=MagicMock(),
        fetch_interval=1,
    )
    bucket, uid = await cs._get_highest_stake_validator_bucket()
    assert bucket is None
    assert uid is None


@pytest.mark.asyncio
async def test_get_highest_stake_validator_bucket_exception():
    """
    Simulate an exception (e.g., in metagraph.uids.tolist()) so that the method
    returns (None, None).
    """
    metagraph = MagicMock()
    # Make uids.tolist() raise an exception.
    metagraph.uids = property(
        lambda self: (_ for _ in ()).throw(Exception("dummy exception"))
    )

    cs = ChainSync(
        config=MagicMock(),
        netuid=1,
        metagraph=metagraph,
        hparams=SimpleNamespace(),
        wallet=MagicMock(),
        fetch_interval=1,
    )

    bucket, uid = await cs._get_highest_stake_validator_bucket()
    assert bucket is None
    assert uid is None


@pytest.mark.asyncio
async def test_get_commitments_outer_exception():
    """
    Simulate an outer exception by patching bt.subtensor so that it raises.
    This covers the outer try/except in get_commitments().
    """
    metagraph = MagicMock()
    metagraph.uids = torch.tensor([1])
    cs = ChainSync(
        config=MagicMock(),
        netuid=1,
        metagraph=metagraph,
        hparams=SimpleNamespace(),
        wallet=MagicMock(),
        fetch_interval=1,
    )
    with patch(
        "tplr.chain_sync.bt.subtensor", side_effect=Exception("outer exception")
    ):
        commitments = await cs.get_commitments()
        # Expect the method to return an empty dict.
        assert commitments == {}


# @pytest.mark.asyncio
# async def test_get_commitments_logger_invalid_length(caplog):
#     """
#     Test that a commitment with an invalid length triggers a log message (warning/error)
#     and skips adding the bucket.

#     The implementation logs a warning with a message including "invalid commitment" (case-insensitive).
#     """
#     # Explicitly set caplog to capture logs from the chain_sync logger.
#     caplog.set_level("WARNING", logger="tplr.chain_sync")
#     metagraph = MagicMock()
#     metagraph.uids = torch.tensor([1])
#     cs = ChainSync(
#         config=MagicMock(),
#         netuid=1,
#         metagraph=metagraph,
#         hparams=SimpleNamespace(),
#         wallet=MagicMock(),
#         fetch_interval=1,
#     )

#     class FakeSubtensor:
#         async def get_commitment(self, netuid, uid):
#             # Return a string whose length is not 128.
#             return "short_commitment"  # length = 16

#     with patch("tplr.chain_sync.bt.subtensor", return_value=FakeSubtensor()):
#         commitments = await cs.get_commitments()

#     # Assert that no bucket was added for UID 1.
#     assert 1 not in commitments, "A bucket was incorrectly added for an invalid commitment length."

#     # Check that a log message was recorded indicating an invalid commitment.
#     logged_msgs = [
#         record.message for record in caplog.records
#         if record.levelname in ("WARNING", "ERROR")
#     ]
#     found = any("invalid commitment" in msg.lower() for msg in logged_msgs)
#     assert found, f"Expected log for invalid commitment length not found. Logged messages: {logged_msgs}"


@pytest.mark.asyncio
async def test_get_commitments_empty_commitment():
    """
    Test that if get_commitment returns an empty string,
    the method skips it without error.
    This covers the branch for `if not commitment or len(commitment) == 0`.
    """
    metagraph = MagicMock()
    metagraph.uids = torch.tensor([1])
    cs = ChainSync(
        config=MagicMock(),
        netuid=1,
        metagraph=metagraph,
        hparams=SimpleNamespace(),
        wallet=MagicMock(),
        fetch_interval=1,
    )

    class FakeSubtensor:
        async def get_commitment(self, netuid, uid):
            return ""  # empty commitment

    with patch("tplr.chain_sync.bt.subtensor", return_value=FakeSubtensor()):
        commitments = await cs.get_commitments()
        # No valid commitment, so expect an empty dict.
        assert commitments == {}


@pytest.mark.asyncio
async def test_get_commitments_no_metagraph():
    """
    Test that if metagraph is None, get_commitments() triggers an exception
    and returns an empty dict.
    Patching bt.subtensor to prevent any network call.
    """
    cs = ChainSync(
        config=MagicMock(),
        netuid=1,
        metagraph=None,
        hparams=SimpleNamespace(),
        wallet=MagicMock(),
        fetch_interval=1,
    )
    with patch("tplr.chain_sync.bt.subtensor", return_value=MagicMock()):
        commitments = await cs.get_commitments()
    assert commitments == {}


@pytest.mark.asyncio
async def test_get_highest_stake_validator_bucket_valid():
    """
    Test that _get_highest_stake_validator_bucket returns the bucket and UID of the highest staked validator.
    In our mock, MockMetagraph(n_validators=10) produces a stake tensor S = [100, 200, ..., 1000];
    hence, the highest stake belongs to uid 9.
    """
    # Set up hyperparameters.
    hparams = SimpleNamespace(
        blocks_per_window=100,
        topk_peers=10,
        minimum_peers=3,
        max_topk_peers=10
    )
    # Create a mock metagraph with 10 validators.
    metagraph = MockMetagraph(n_validators=10)
    # Create a dummy wallet.
    wallet = MockWallet()
    # Instantiate ChainSync with the mocks.
    cs = ChainSync(
        config=MagicMock(),
        netuid=1,
        metagraph=metagraph,
        hparams=hparams,
        wallet=wallet
    )
    # Set commitments so that only uid 9 has a valid bucket.
    dummy_bucket = Bucket(
        name="bucket9",
        account_id="acc9",
        access_key_id="key9",
        secret_access_key="secret9"
    )
    cs.commitments = {9: dummy_bucket}

    # Ensure get_bucket returns from the commitments dictionary (if not already defined).
    if not hasattr(cs, "get_bucket") or cs.get_bucket is None:
        cs.get_bucket = lambda uid: cs.commitments.get(uid)

    bucket, uid = await cs._get_highest_stake_validator_bucket(refresh_commitments=False)
    
    assert uid == 9, f"Expected highest staked validator uid to be 9, got {uid}"
    assert bucket == dummy_bucket, "Returned bucket does not match expected dummy bucket"
    
    # TODO: Add tests for cases when multiple commitments exist or refresh_commitments is True.
